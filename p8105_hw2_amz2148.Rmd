---
title: "p8105_hw2_amz2148"
output: github_document
---

Homework 2

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #shows all code chunks
```

# Problem 0

```{r load_libraries}
library(tidyverse) #loads tidyverse package
library(readxl) #loads readxl package
```

# Problem 1

First we read, clean, and re-format (where needed) the data. We also retain only certain variables as instructed.

```{r}
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% #reads in file, routes8-11 were in double format so changed to character
  janitor::clean_names() %>% #cleans variable names
  select(line, station_name, station_latitude, station_longitude, 
         starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% #retains only the listed variables
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) #converts entry variable to logical type
```

With only these steps so far, the data is not tidy because the route1:route11 variables should be condensed into a long-format "route" variable that has the route number as values and a second variable that has the subway line (e.g., A, C, 1, 2, etc.) corresponding to that route. This non-tidy dataset has ``r nrow(trans_ent)`` rows (observations) and ``r ncol(trans_ent)`` columns (variables) including ``r names(trans_ent)``. To obtain this dataset from the original csv file, we read the file into R, changed the column types to character for route8:route11 (as these were originally in the double format), used the clean_names function to clean-up the variable names, and retained only certain variables. Finally, we used the mutate and ifelse functions to turn the entry variable into a logical variable from an original character type. 

```{r}
trans_ent %>% #df
  select(station_name, line) %>% #selecting only station_name and line variables
  distinct #identifying only observations with distinct values for this combination of variables
```

There are 465 distinct stations. This can be found using the distinct function by conditioning on station_name AND line (meaning a station will be considered distinct if the combination of station_name and line are different from all other stations).

```{r}
trans_ent %>%  #df
  filter(ada == TRUE) %>% #filtering only data where ADA compliance is true
  select(station_name, line) %>% #selecting only station_name and line variables
  distinct #identifying only observations with distinct values for this combination of variables
```

There are 84 ADA-compliant, distinct stations. This is the same as the previous step, but also includes the pre-qualifier before selecting for distinct stations that only ADA-compliant stations should be taken into consideration.

```{r}
trans_ent %>%  #df
  filter(vending == "NO") %>% #filtering only data without vending
  pull(entry) %>% #pulling only entry as a vector
  mean #mean of entry=true
```

37.7% of station entrances and exits without vending allow entrance. This can be determined by pulling the number of station observations where entry is true, but first using "no vending" as a prequalifier.

```{r}
trans_ent %>%  #df
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% #convert data to longer format with route variables
  filter(route_name == "A") %>% #filtering only data where the route name is A
  select(station_name, line) %>% #selecting only these two variables
  distinct #identifying only distinct stations based on station_name and line
```

60 distinct stations serve the A train.

```{r}
trans_ent %>%  #df
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% #convert data to longer format with route variables
  filter(route_name == "A", ada == TRUE) %>% #filtering only data where the route name is A and where ADA compliance is true
  select(station_name, line) %>% #selecting only these two variables
  distinct #identifying only distinct stations based on station_name and line
```

Of the 60 distinct stations that serve the A train, 17 distinct stations are ADA compliant.


# Problem 2

First we read and clean the data from the Mr. Trash Wheel sheet under the following specifications:

* specifying the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* using reasonable variable names
* omitting rows that do not include dumpster-specific data
* rounding the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
* adding an additional variable to mark source of data (Mr. vs. Professor sheet)

```{r mr}
mr_trashwheel = 
  read_excel("data/Trash Wheel Collection Data.xlsx", range = "Mr. Trash Wheel!A2:N549") %>% #reads in only desired section and sheet from excel document
  janitor::clean_names()  %>% #cleans variable names
  drop_na(dumpster) %>% #removes rows with missing values for "dumpster" variable
  mutate(sports_balls = as.integer(sports_balls)) %>% #makes "sports_balls" variable an integer
  mutate(machine = "mister") %>% #creates new variable to identify sheet/source of data 
  mutate(year = as.double(year)) #converts character year variable to double
```

Then, we import, clean, and organize the data from the Professor Trash Wheel sheet.

```{r professor}
prof_trashwheel = 
  read_excel("data/Trash Wheel Collection Data.xlsx", range = "Professor Trash Wheel!A2:M96") %>% #reads in only desired section and sheet from excel document
  janitor::clean_names()  %>% #cleans variable names
  drop_na(dumpster) %>% #removes rows with missing values for "dumpster" variable
  mutate(machine = "professor") #creates new variable to identify sheet/source of data 
```

Finally, we combine the Mr. Trash Wheel and Professor Trash Wheel datasets to produce a single tidy dataset.

```{r bind}
trashwheel_tidy = 
  bind_rows(mr_trashwheel, prof_trashwheel) %>% #combines two datasets into one
  janitor::clean_names() %>% #cleans variable names
  select(machine, dumpster, everything()) %>% #reorders columns
  arrange(machine, dumpster) #sorts data by machine name and dumpster number
```

In the resulting dataset, there are ``r nrow(trashwheel_tidy)`` rows (observations) of which ``r nrow(subset(trashwheel_tidy,machine == "mister"))`` observations are from the Mr. Trashwheel dataset and ``r nrow(subset(trashwheel_tidy,machine == "professor"))`` observations are from the Professor Trashwheel dataset. The combined dataset has ``r ncol(trashwheel_tidy)`` variables of which one is new: ``machine`` which identifies which dataset the observation is from. Other important variables include ``date``, ``dumpster``, ``weight_tons``, ``volume_cubic_yards``, and ``homes_powered``. The total weight of trash collected by Professor Trashwheel was ``r sum(trashwheel_tidy[trashwheel_tidy$machine == "professor",]$weight_tons)`` tons. The total number of sports balls collected by Mr. Trash Wheel in 2020 was ``r sum(trashwheel_tidy[trashwheel_tidy$machine == "mister" & trashwheel_tidy$year == "2020",]$sports_balls)`` balls.


# Problem 3

First, we clean the data from the pols-month.csv file. We use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r pols_month}
pols_month = 
  read_csv(file = "data/fivethirtyeight_datasets/pols-month.csv") %>% #reads in csv file
  janitor::clean_names() %>% #cleans variable names
  separate(mon, into = c("year", "month", "day"), sep = '-') %>% #separates mon variable into year, month, day variables
  mutate(month = as.numeric(month), year = as.numeric(year), day = as.numeric(day)) %>% #converts new variables from character to numeric
  mutate(month = month.abb[month]) %>% #replaces month number with name
  mutate(month = factor(month, levels = month.abb)) %>% #converts month name to factor variable
  mutate(president = case_when(prez_dem == 1 ~ "dem", 
    prez_dem != 1 ~ "gop")) %>% #creates new president variable
  select(-prez_dem, -prez_gop, -day) %>% #removes prez_dem, prez_gap, and day variables
  arrange(year, month) #sorts data by year and month
```

Second, we clean the data in snp.csv using a similar process. For consistency across datasets, we arrange the data according to year and month, and organize so that year and month are the leading columns.

```{r snp}
snp = 
  read_csv(file = "data/fivethirtyeight_datasets/snp.csv") %>% #reads in csv file
  janitor::clean_names() %>% #cleans variable names
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  mutate(year = ifelse(year > 15, paste("19",year, sep = ""), paste("20",year, sep = ""))) %>% 
  mutate(month = as.numeric(month), year = as.numeric(year)) %>% #converts month and year variables from character to numeric
  mutate(month = month.abb[month]) %>% #replaces month number with name
  mutate(month = factor(month, levels = month.abb)) %>% #converts month name to factor variable
  select(-day) %>% #removes day variable
  select(year, month, everything()) %>% #reorders columns
  arrange(year, month) #sorts data by year and month
```

Third, we tidy the unemployment data so that it can be merged with the previous datasets. This process involves switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r unemployment}
unemployment = 
  read_csv(file = "data/fivethirtyeight_datasets/unemployment.csv") %>% #reads in csv file
  rename(year = Year) %>% #changes case of year variable to lowercase (keeping months uppercase for later ease of merging with other files)
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemployment_rate") %>% 
  mutate(month = factor(month, levels = month.abb)) #converts month name to factor variable
```

Finally, we join the datasets by merging snp into pols, then merging unemployment into the result.

```{r join}
pols_snp = left_join(pols_month, snp, by = c("year", "month")) #left join adds snp data into pols_month dataset

pols_snp_unemp = left_join(pols_snp, unemployment, by = c("year", "month")) #left join adds unemployment data into pols_snp dataset
```

The ``pols_month`` dataset included ``r nrow(pols_month)`` rows (observations) and ``r ncol(pols_month)`` columns (variables) including ``r names(pols_month)``. The data begins in January 1947 and ends in June 2015. It describes the number of Republican and Democrat governors, senators, and representatives as well as the political party of the president.

The ``snp`` dataset included ``r nrow(snp)`` rows (observations) and ``r ncol(snp)`` columns (variables) including ``r names(snp)``. The data begins in January 1950 and ends in July 2015. It describes the closing values of the S&P stock index from each associated date.

The ``unemployment`` dataset included ``r nrow(unemployment)`` rows (observations) and ``r ncol(unemployment)`` columns (variables) including ``r names(unemployment)``. The data begins in January 1948 and ends in December 2015. It describes the percentage of unemployment from each associated date.

The ``pols_snp_unemp`` dataset included ``r nrow(pols_snp_unemp)`` rows (observations) and ``r ncol(pols_snp_unemp)`` columns (variables) including ``r names(pols_snp_unemp)``. The dataset overall starts in January 1947 and ends in June 2015 as we created it by left_joining files to the ``pols_month`` dataset, whose range is carried over to the merged dataset. However, observations originally from the ``snp`` dataset only start in January 1950 in the merged dataset and observations originally from the ``unemployment`` dataset only start in January 1950 in the merged dataset.
