p8105_hw2_amz2148
================

Homework 2

# Problem 0

``` r
library(tidyverse) #loads tidyverse package
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl) #loads readxl package
```

# Problem 1

First we read, clean, and re-format (where needed) the data. We also
retain only certain variables as instructed.

``` r
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% #reads in file, routes8-11 were in double format so changed to character
  janitor::clean_names() %>% #cleans variable names
  select(line, station_name, station_latitude, station_longitude, 
         starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% #retains only the listed variables
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) #converts entry variable to logical type
```

With only these steps so far, the data is not tidy because the
route1:route11 variables should be condensed into a long-format “route”
variable that has the route number as values and a second variable that
has the subway line (e.g., A, C, 1, 2, etc.) corresponding to that
route. This non-tidy dataset has `1868` rows (observations) and `20`
columns (variables) including
`line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, exit_only, vending, entrance_type, ada`.
To obtain this dataset from the original csv file, we read the file into
R, changed the column types to character for route8:route11 (as these
were originally in the double format), used the clean_names function to
clean-up the variable names, and retained only certain variables.
Finally, we used the mutate and ifelse functions to turn the entry
variable into a logical variable from an original character type.

``` r
trans_ent %>% #df
  select(station_name, line) %>% #selecting only station_name and line variables
  distinct #identifying only observations with distinct values for this combination of variables
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

There are 465 distinct stations. This can be found using the distinct
function by conditioning on station_name AND line (meaning a station
will be considered distinct if the combination of station_name and line
are different from all other stations).

``` r
trans_ent %>%  #df
  filter(ada == TRUE) %>% #filtering only data where ADA compliance is true
  select(station_name, line) %>% #selecting only station_name and line variables
  distinct #identifying only observations with distinct values for this combination of variables
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

There are 84 ADA-compliant, distinct stations. This is the same as the
previous step, but also includes the pre-qualifier before selecting for
distinct stations that only ADA-compliant stations should be taken into
consideration.

``` r
trans_ent %>%  #df
  filter(vending == "NO") %>% #filtering only data without vending
  pull(entry) %>% #pulling only entry as a vector
  mean #mean of entry=true
```

    ## [1] 0.3770492

37.7% of station entrances and exits without vending allow entrance.
This can be determined by pulling the number of station observations
where entry is true, but first using “no vending” as a prequalifier.

``` r
trans_ent %>%  #df
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% #convert data to longer format with route variables
  filter(route_name == "A") %>% #filtering only data where the route name is A
  select(station_name, line) %>% #selecting only these two variables
  distinct #identifying only distinct stations based on station_name and line
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

60 distinct stations serve the A train.

``` r
trans_ent %>%  #df
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% #convert data to longer format with route variables
  filter(route_name == "A", ada == TRUE) %>% #filtering only data where the route name is A and where ADA compliance is true
  select(station_name, line) %>% #selecting only these two variables
  distinct #identifying only distinct stations based on station_name and line
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

Of the 60 distinct stations that serve the A train, 17 distinct stations
are ADA compliant.

# Problem 2

First we read and clean the data from the Mr. Trash Wheel sheet under
the following specifications:

-   specifying the sheet in the Excel file and to omit non-data entries
    (rows with notes / figures; columns containing notes) using
    arguments in read_excel
-   using reasonable variable names
-   omitting rows that do not include dumpster-specific data
-   rounding the number of sports balls to the nearest integer and
    converts the result to an integer variable (using as.integer)
-   adding an additional variable to mark source of data
    (Mr. vs. Professor sheet)

``` r
mr_trashwheel = 
  read_excel("data/Trash Wheel Collection Data.xlsx", range = "Mr. Trash Wheel!A2:N549") %>% #reads in only desired section and sheet from excel document
  janitor::clean_names()  %>% #cleans variable names
  drop_na(dumpster) %>% #removes rows with missing values for "dumpster" variable
  mutate(sports_balls = as.integer(sports_balls)) %>% #makes "sports_balls" variable an integer
  mutate(machine = "mister") %>% #creates new variable to identify sheet/source of data 
  mutate(year = as.double(year)) #converts character year variable to double
```

Then, we import, clean, and organize the data from the Professor Trash
Wheel sheet.

``` r
prof_trashwheel = 
  read_excel("data/Trash Wheel Collection Data.xlsx", range = "Professor Trash Wheel!A2:M96") %>% #reads in only desired section and sheet from excel document
  janitor::clean_names()  %>% #cleans variable names
  drop_na(dumpster) %>% #removes rows with missing values for "dumpster" variable
  mutate(machine = "professor") #creates new variable to identify sheet/source of data 
```

Finally, we combine the Mr. Trash Wheel and Professor Trash Wheel
datasets to produce a single tidy dataset.

``` r
trashwheel_tidy = 
  bind_rows(mr_trashwheel, prof_trashwheel) %>% #combines two datasets into one
  janitor::clean_names() %>% #cleans variable names
  select(machine, dumpster, everything()) %>% #reorders columns
  arrange(machine, dumpster) #sorts data by machine name and dumpster number
```

In the resulting dataset, there are `641` rows (observations) of which
`547` observations are from the Mr. Trashwheel dataset and `94`
observations are from the Professor Trashwheel dataset. The combined
dataset has `15` variables of which one is new: `machine` which
identifies which dataset the observation is from. Other important
variables include `date`, `dumpster`, `weight_tons`,
`volume_cubic_yards`, and `homes_powered`. The total weight of trash
collected by Professor Trashwheel was `190.12` tons. The total number of
sports balls collected by Mr. Trash Wheel in 2020 was `856` balls.

# Problem 3

First, we clean the data from the pols-month.csv file. We use separate()
to break up the variable mon into integer variables year, month, and
day; replace month number with month name; create a president variable
taking values gop and dem, and remove prez_dem and prez_gop; and remove
the day variable.

``` r
pols_month = 
  read_csv(file = "data/fivethirtyeight_datasets/pols-month.csv") %>% #reads in csv file
  janitor::clean_names() %>% #cleans variable names
  separate(mon, into = c("year", "month", "day"), sep = '-') %>% #separates mon variable into year, month, day variables
  mutate(month = as.numeric(month), year = as.numeric(year), day = as.numeric(day)) %>% #converts new variables from character to numeric
  mutate(month = month.abb[month]) %>% #replaces month number with name
  mutate(month = factor(month, levels = month.abb)) %>% #converts month name to factor variable
  mutate(president = case_when(prez_dem == 1 ~ "dem", 
    prez_dem != 1 ~ "gop")) %>% #creates new president variable
  select(-prez_dem, -prez_gop, -day) %>% #removes prez_dem, prez_gap, and day variables
  arrange(year, month) #sorts data by year and month
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Second, we clean the data in snp.csv using a similar process. For
consistency across datasets, we arrange the data according to year and
month, and organize so that year and month are the leading columns.

``` r
snp = 
  read_csv(file = "data/fivethirtyeight_datasets/snp.csv") %>% #reads in csv file
  janitor::clean_names() %>% #cleans variable names
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  mutate(year = ifelse(year > 15, paste("19",year, sep = ""), paste("20",year, sep = ""))) %>% 
  mutate(month = as.numeric(month), year = as.numeric(year)) %>% #converts month and year variables from character to numeric
  mutate(month = month.abb[month]) %>% #replaces month number with name
  mutate(month = factor(month, levels = month.abb)) %>% #converts month name to factor variable
  select(-day) %>% #removes day variable
  select(year, month, everything()) %>% #reorders columns
  arrange(year, month) #sorts data by year and month
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Third, we tidy the unemployment data so that it can be merged with the
previous datasets. This process involves switching from “wide” to “long”
format; ensuring that key variables have the same name; and ensuring
that key variables take the same values.

``` r
unemployment = 
  read_csv(file = "data/fivethirtyeight_datasets/unemployment.csv") %>% #reads in csv file
  rename(year = Year) %>% #changes case of year variable to lowercase (keeping months uppercase for later ease of merging with other files)
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemployment_rate") %>% 
  mutate(month = factor(month, levels = month.abb)) #converts month name to factor variable
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Finally, we join the datasets by merging snp into pols, then merging
unemployment into the result.

``` r
pols_snp = left_join(pols_month, snp, by = c("year", "month")) #left join adds snp data into pols_month dataset

pols_snp_unemp = left_join(pols_snp, unemployment, by = c("year", "month")) #left join adds unemployment data into pols_snp dataset
```

The `pols_month` dataset included `822` rows (observations) and `9`
columns (variables) including
`year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president`.
The data begins in January 1947 and ends in June 2015. It describes the
number of Republican and Democrat governors, senators, and
representatives as well as the political party of the president.

The `snp` dataset included `787` rows (observations) and `3` columns
(variables) including `year, month, close`. The data begins in January
1950 and ends in July 2015. It describes the closing values of the S&P
stock index from each associated date.

The `unemployment` dataset included `816` rows (observations) and `3`
columns (variables) including `year, month, unemployment_rate`. The data
begins in January 1948 and ends in December 2015. It describes the
percentage of unemployment from each associated date.

The `pols_snp_unemp` dataset included `822` rows (observations) and `11`
columns (variables) including
`year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment_rate`.
The dataset overall starts in January 1947 and ends in June 2015 as we
created it by left_joining files to the `pols_month` dataset, whose
range is carried over to the merged dataset. However, observations
originally from the `snp` dataset only start in January 1950 in the
merged dataset and observations originally from the `unemployment`
dataset only start in January 1950 in the merged dataset.
